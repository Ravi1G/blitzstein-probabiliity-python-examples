{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief summary\n",
    "\n",
    "### Summaries of a distribution\n",
    "\n",
    "#### Median\n",
    "\n",
    "We say that $c$ is a *median* of an r.v. $X$ if $P(X \\leq c) \\geq 1/2$ and $P(X \\geq c) \\geq 1/2$. (The simplest way this can happen is if the CDF of $X$ hits 1/2 exactly at $c$, but we know that some CDFs have jumps.)\n",
    "\n",
    "#### Mode\n",
    "\n",
    "For a discrete r.v. $X$, we say that $c$ is a *mode* of $X$ if it maximizes the PMF: $P(X=c) \\geq P(X=x)$ for all $x$. For a continuous r.v. $X$ with PDF $f$, we say that $c$ is a mode if it maximizes the PDF: $f(c) \\geq f(x)$ for all $x$.\n",
    "\n",
    "- The value of $c$ that minimizes the mean squared error $E(X-c)^2$ is $c = \\mu$.\n",
    "- A value of $c$ that minimizes the mean absolute error $E|X-c|$ is $c = m$.\n",
    "\n",
    "### Kinds of moments\n",
    "\n",
    "Let $X$ be a r.v. with mean $\\mu$ and variance $\\sigma^2$. For any positive integer $n$, the $n$th *moment* of $X$ is $E(X^n)$, the $n$th *central moment* is $E((X-\\mu)^n)$, and the $n$th *standardized moment* is $E(\\big(\\frac{X-\\mu}{\\sigma}\\big)^n)$. Throughout the previous sentence, \"if it exists\" is left implicit.\n",
    "\n",
    "- The mean is the first moment.\n",
    "- The variance is the second central moment.\n",
    "\n",
    "#### Skewness\n",
    "\n",
    "The *skewness* of a r.v. $X$ with mean $\\mu$ and variance $\\sigma^2$ is the third standardized moment of $X$:\n",
    "\n",
    "\\begin{equation}\n",
    "Skew(X) = E\\big(\\frac{X-\\mu}{\\sigma}\\big)^3.\n",
    "\\end{equation}\n",
    "\n",
    "#### Symmetric of a r.v.\n",
    "\n",
    "We say that a r.v. $X$ has a *symmetric distribution about* $\\mu$ if $X - \\mu$ has the same distribution as $\\mu - X$. We also say that $X$ is symmetric or that the distribution of $X$ is symmetric; these all have the same meaning.\n",
    "\n",
    "- A continuous r.v. X is symmetric about $\\mu$ if and only if $f(x) = f(2\\mu-x)$ for all $x$.\n",
    "\n",
    "#### Kurtosis\n",
    "\n",
    "The *kurtosis* of a r.v. $X$ with mean $\\mu$ and variance $\\sigma^2$ is a shifted version of the fourth standardized moment of $X$:\n",
    "\n",
    "\\begin{equation}\n",
    "Kurt(X) = E\\big(\\frac{X-\\mu}{\\sigma}\\big)^4 - 3.\n",
    "\\end{equation}\n",
    "\n",
    "### Sample moments\n",
    "\n",
    "Let $X_1, ..., X_n$ be i.i.d random variables. The $k$th *sample moment* is the r.v.\n",
    "\n",
    "\\begin{equation}\n",
    "M_k = \\frac{1}{n} \\sum_{j=1}^{n} X_j^k.\n",
    "\\end{equation}\n",
    "\n",
    "The *sample mean* $\\bar{X}_n$ is the first sample moment:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bar{X}_n = \\frac{1}{n} \\sum_{j=1}^{n} X_j.\n",
    "\\end{equation}\n",
    "\n",
    "In contrast, the *population mean* or *true mean* is $E(X_j)$, the mean of the distribution from which the $X_j$ were drawn.\n",
    "\n",
    "#### Mean and variance of sample mean\n",
    "\n",
    "Let $X_1, ..., X_n$ be i.i.d. r.v.s with mean $\\mu$ and variance $\\sigma^2$. Then the sample mean $\\bar{X}_n$ is unbiased for estimating $\\mu$. That is,\n",
    "\n",
    "\\begin{equation}\n",
    "E(\\bar{X}_n) = \\mu.\n",
    "\\end{equation}\n",
    "\n",
    "The variance of $\\bar{X}_n$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    "Var(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n",
    "\\end{equation}\n",
    "\n",
    "#### Sample variance and sample standard deviation\n",
    "\n",
    "Let $X_1, ..., X_n$ be i.i.d. random variables with mean $\\mu$ and variance $\\sigma^2$. The *sample variance* is the r.v. \n",
    "\n",
    "\\begin{equation}\n",
    "S_n^2 = \\frac{1}{n-1} \\sum_{j=1}^{n} (X_j-\\bar{X}_n)^2.\n",
    "\\end{equation}\n",
    "\n",
    "and the sample variance $S_n^2$ is unbiased for estimating $\\sigma^2$, i.e.,\n",
    "\n",
    "\\begin{equation}\n",
    "E(S_n^2) = \\sigma^2.\n",
    "\\end{equation}\n",
    "\n",
    "The *sample standard deviation* is the square root of the sample variance.\n",
    "\n",
    "#### Sample skewness and sample kurtosis\n",
    "\n",
    "We can define the *sample skewness* to be\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\frac{1}{n} \\sum_{j=1}^{n} (X_j-\\bar{X}_n)^3} {S_n^3},\n",
    "\\end{equation}\n",
    "\n",
    "and the *sample kurtosis* to be\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\frac{1}{n} \\sum_{j=1}^{n} (X_j-\\bar{X}_n)^4} {S_n^4} - 3.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Moment generating functions\n",
    "\n",
    "The *moment generating function* (MGF) of a r.v. $X$ is $M(t) = E(e^{tX})$, as a function of $t$, if this is finite on some open interval $(-a, a)$ containing $0$. Otherwise we say the MGF of $X$ does not exist.\n",
    "\n",
    "#### Bernoulli MGF\n",
    "\n",
    "For $X \\sim Bern(p)$, $M(t) = E(e^{tX}) = pe^t + q$, which is finite for all values of $t$.\n",
    "\n",
    "#### Geometric MGF\n",
    "\n",
    "For $X \\sim Geom(p)$,\n",
    "\n",
    "\\begin{equation}\n",
    "M(t) = E(e^{tX}) = \\sum_{k=0}^{\\infty} e^{tk}q^kp = p\\sum_{k=0}^{\\infty}(qe^t)^k = \\frac{p}{1-qe^t}\n",
    "\\end{equation}\n",
    "\n",
    "for $qe^t < 1$, i.e., for $t$ in $(-\\infty, log(1/q))$.\n",
    "\n",
    "#### Uniform MGF\n",
    "\n",
    "Let $U \\sim Unif(a,b)$. Then the MGF of $U$ is \n",
    "\n",
    "\\begin{equation}\n",
    "M(t) = E(e^{tU}) = \\frac{1}{b-a} \\int_a^b e^{tu}du = \\frac{e^{tb}-e^{ta}} {t(b-a)}\n",
    "\\end{equation}\n",
    "\n",
    "for $t \\neq 0$, and $M(0) = 1$.\n",
    "\n",
    "### Moments via derivatives of the MGF\n",
    "\n",
    "Given the MGF of $X$, we can get the $n$th moment of $X$ by evaluating the $n$th derivative of the MGF at $0$: $E(X^n) = M^{(n)}(0)$.\n",
    "\n",
    "#### MGF determines the distribution\n",
    "\n",
    "The MGF of a random variable determines its distribution: if two r.v.s have the same MGF, they must have the same distribution.\n",
    "\n",
    "#### MGF of a sum of independent r.v.s\n",
    "\n",
    "If $X$ and $Y$ are independent, then the MGF of $X+Y$ is the product of the individual MGFs:\n",
    "\n",
    "\\begin{equation}\n",
    "M_{X+Y}(t) = M_X(t)+M_Y(t).\n",
    "\\end{equation}\n",
    "\n",
    "#### Binomial MGF\n",
    "\n",
    "The MGF of a $Bern(p)$ r.v. is $pe^t+q$, so the MGF of a $Bin(n,p)$ r.v. is\n",
    "\n",
    "\\begin{equation}\n",
    "M(t) = (pe^t+q)^n.\n",
    "\\end{equation}\n",
    "\n",
    "#### Negative Binomial MGF\n",
    "\n",
    "The MGF of a $Geom(p)$ r.v. is $\\frac{p}{1-qe^t}$ for $qe^t < 1$, so the MGF of $X \\sim NBin(r,p)$ is\n",
    "\n",
    "\\begin{equation}\n",
    "M(t) = \\big(\\frac{p}{1-qe^t}\\big)^r\n",
    "\\end{equation}\n",
    "\n",
    "for $qe^t < 1$.\n",
    "\n",
    "#### Normal MGF\n",
    "\n",
    "The MGF of a standard Normal r.v. Z is \n",
    "\n",
    "\\begin{equation}\n",
    "M_Z(t) = E(e^{tZ}) = \\int_{-\\infty}^{\\infty} e^{tz}\\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}dz = e^{t^2/2}.\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the MGF of $X = \\mu + \\sigma Z \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is\n",
    "\n",
    "\\begin{equation}\n",
    "M_X(t) = e^{\\mu t}M_Z(\\sigma t) = e^{\\mu t}e^{(\\sigma t)^2/2} = e^{\\mu t + \\frac{1}{2} \\sigma^2 t^2}.\n",
    "\\end{equation}\n",
    "\n",
    "#### Exponential MGF\n",
    "\n",
    "The MGF of $X \\sim Expo(1)$ is \n",
    "\n",
    "\\begin{equation}\n",
    "M(t) = E(e^{tX}) = \\int_{0}^{\\infty} e^{tx}e^{-x}dx = \\int_{0}^{\\infty} e^{-x(1-t)}dx = \\frac{1}{1-t}\\ \\text{for}\\ t < 1.\n",
    "\\end{equation}\n",
    "\n",
    "So the MGF of $Y = X/\\lambda \\sim Expo(\\lambda)$ is \n",
    "\n",
    "\\begin{equation}\n",
    "M_Y(t) = M_X\\big(\\frac{t}{\\lambda}\\big) = \\frac{\\lambda}{\\lambda-t}\\ \\text{for}\\ t < \\lambda.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## Python examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, uniform, poisson, expon, binom\n",
    "from scipy.integrate import quad\n",
    "from scipy import optimize\n",
    "from numpy.random import choice\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.000000000000004, 4.4229308200406246e-09)\n"
     ]
    }
   ],
   "source": [
    "# The 6th moment of a N(0, 1)\n",
    "g = lambda x: x**6*norm.pdf(x)\n",
    "print(quad(g, -np.inf, np.inf))   # (hhe integral, an estimate of the absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3333333333333333, 3.700743415417188e-15)\n"
     ]
    }
   ],
   "source": [
    "# The 2nd moment of a Unif(-1, 1)\n",
    "h = lambda x: x**2*uniform.pdf(x, loc=-1.0, scale=2.0)\n",
    "print(quad(h, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.0\n"
     ]
    }
   ],
   "source": [
    "# The 2nd moment of X ~ Pois(7)\n",
    "g = lambda k: k**2*poisson.pmf(k, 7)\n",
    "print(np.sum([g(x) for x in np.arange(100)]))   # The total contribution of all the terms after k=100 is negligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.841877935\n"
     ]
    }
   ],
   "source": [
    "# The 6th sample moment of 100 i.i.d. N(0,1) r.v.s\n",
    "X = norm.rvs(size=100)\n",
    "print(np.mean(X**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0457364860542\n",
      "1.04088400025\n"
     ]
    }
   ],
   "source": [
    "# Using the sample mean and sample variance to estimate the true mean and true variance\n",
    "# Generate 1000 examples from a N(0, 1)\n",
    "Z = norm.rvs(size=1000)\n",
    "print(np.mean(Z))   # ~= 0\n",
    "print(np.var(Z))       # ~= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skewness and kurtosis\n",
    "skew = lambda X: np.mean((X - np.mean(X)) ** 3) / np.std(X) ** 3\n",
    "kurt = lambda X: np.mean((X - np.mean(X)) ** 4) / np.std(X) ** 4 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medians and modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n"
     ]
    }
   ],
   "source": [
    "# Find the median of the Expo(1) by finding a root of PDF\n",
    "g = lambda x: expon.pdf(x) - 1/2.\n",
    "print(optimize.brentq(g, 0, 1))    # (function, lowerbound, upperbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n"
     ]
    }
   ],
   "source": [
    "# Find the median of the Expo(1)\n",
    "print(expon.ppf(1/2.))   # calls quantile function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.00000002]\n"
     ]
    }
   ],
   "source": [
    "# Find the mode of the Gamma(6,1) distribution by maximizing PDF\n",
    "h = lambda x: -x**5*np.exp(-x)\n",
    "print(optimize.minimize(h, 1).x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Find the median of the Bin(50, 0.2) distribution \n",
    "n, p = 50, 0.2\n",
    "print(np.argmax(binom.cdf(np.arange(n), n, p) >= 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_trials = 10**6\n",
    "results = []\n",
    "for i in range(num_trials):\n",
    "    results.append(np.sum(np.random.choice(np.arange(1, 7), size=6, replace=True)))\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.073564\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(results == 18) / float(num_trials))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
